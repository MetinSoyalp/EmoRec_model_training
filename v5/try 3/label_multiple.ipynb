{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "import torch\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, f1_score, precision_score, recall_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"./go_emotion_dataset/goemotion_train_i2.csv\", sep=';')\n",
    "\n",
    "not_chosen_columns = ['ID', 'Tweet']\n",
    "label_columns = [col for col in df_test.columns if col not in not_chosen_columns]\n",
    "\n",
    "df_labels_test = df_test[label_columns]\n",
    "\n",
    "list_labels_test = df_labels_test.values.tolist()\n",
    "\n",
    "test_id = df_test['ID'].tolist()\n",
    "\n",
    "test_texts = df_test['Tweet'].tolist()\n",
    "test_labels = list_labels_test\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"saved_model_try_6_i2\")\n",
    "model = BertForSequenceClassification.from_pretrained(\"saved_model_try_6_i2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "all_predictions = []\n",
    "\n",
    "# Process each text\n",
    "for text in test_texts:\n",
    "    inputs = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    inputs = inputs.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    probabilities = torch.sigmoid(logits)  # Apply sigmoid to convert logits to probabilities\n",
    "    probabilities = probabilities.squeeze(0)\n",
    "    probabilities = probabilities.tolist()\n",
    "\n",
    "    all_predictions.append(probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.array(all_predictions)\n",
    "\n",
    "anger = a[:,0].tolist()\n",
    "anticipation = a[:,1].tolist()\n",
    "disgust = a[:,2].tolist()\n",
    "fear = a[:,3].tolist()\n",
    "joy = a[:,4].tolist()\n",
    "love = a[:,5].tolist()\n",
    "optimism = a[:,6].tolist()\n",
    "pessimism = a[:,7].tolist()\n",
    "sadness = a[:,8].tolist()\n",
    "surprise = a[:,9].tolist()\n",
    "trust = a[:,10].tolist()\n",
    "\n",
    "pseudo_labeled_dataset = pd.DataFrame({\n",
    "    'ID': test_id,\n",
    "    'Tweet': test_texts,\n",
    "    'anger': anger,\n",
    "    'anticipation': anticipation,\n",
    "    'disgust': disgust,\n",
    "    'fear': fear,\n",
    "    'joy': joy,\n",
    "    'love': love,\n",
    "    'optimism': optimism,\n",
    "    'pessimism': pessimism,\n",
    "    'sadness': sadness,\n",
    "    'surprise': surprise,\n",
    "    'trust': trust\n",
    "})\n",
    "\n",
    "pseudo_labeled_dataset.to_csv('pseudo_labeled_dataset_i1.csv', encoding='utf_8', index=False, sep=';')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_7388\\3572191288.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  pseudo_labeled_dataset.sort_values(by='trust', ascending=False)[pseudo_labeled_dataset['trust'] > 0.65]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>anger</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>love</th>\n",
       "      <th>optimism</th>\n",
       "      <th>pessimism</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11708</th>\n",
       "      <td>ed19t6a</td>\n",
       "      <td>Anything is a dildo of you're brave enough</td>\n",
       "      <td>0.077933</td>\n",
       "      <td>0.122461</td>\n",
       "      <td>0.046029</td>\n",
       "      <td>0.173902</td>\n",
       "      <td>0.108056</td>\n",
       "      <td>0.110631</td>\n",
       "      <td>0.501548</td>\n",
       "      <td>0.072085</td>\n",
       "      <td>0.054894</td>\n",
       "      <td>0.046368</td>\n",
       "      <td>0.852423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18457</th>\n",
       "      <td>ee2flql</td>\n",
       "      <td>Alway protect yourself</td>\n",
       "      <td>0.090108</td>\n",
       "      <td>0.139424</td>\n",
       "      <td>0.051258</td>\n",
       "      <td>0.156635</td>\n",
       "      <td>0.099426</td>\n",
       "      <td>0.103484</td>\n",
       "      <td>0.469578</td>\n",
       "      <td>0.075968</td>\n",
       "      <td>0.064776</td>\n",
       "      <td>0.046545</td>\n",
       "      <td>0.838971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16187</th>\n",
       "      <td>ed8ma5b</td>\n",
       "      <td>Thank you for providing an unbiased &amp; sensible...</td>\n",
       "      <td>0.078899</td>\n",
       "      <td>0.140619</td>\n",
       "      <td>0.052820</td>\n",
       "      <td>0.121172</td>\n",
       "      <td>0.099130</td>\n",
       "      <td>0.104772</td>\n",
       "      <td>0.321970</td>\n",
       "      <td>0.105711</td>\n",
       "      <td>0.081425</td>\n",
       "      <td>0.068242</td>\n",
       "      <td>0.838406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14876</th>\n",
       "      <td>eefvvg0</td>\n",
       "      <td>Respect for the pedes</td>\n",
       "      <td>0.107745</td>\n",
       "      <td>0.111379</td>\n",
       "      <td>0.058363</td>\n",
       "      <td>0.107954</td>\n",
       "      <td>0.075680</td>\n",
       "      <td>0.135611</td>\n",
       "      <td>0.324404</td>\n",
       "      <td>0.083293</td>\n",
       "      <td>0.068631</td>\n",
       "      <td>0.070732</td>\n",
       "      <td>0.826014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12620</th>\n",
       "      <td>efcqm9e</td>\n",
       "      <td>Thank you for your advice!</td>\n",
       "      <td>0.071449</td>\n",
       "      <td>0.109628</td>\n",
       "      <td>0.045809</td>\n",
       "      <td>0.110659</td>\n",
       "      <td>0.094731</td>\n",
       "      <td>0.127368</td>\n",
       "      <td>0.294822</td>\n",
       "      <td>0.108275</td>\n",
       "      <td>0.082804</td>\n",
       "      <td>0.063430</td>\n",
       "      <td>0.823668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4284</th>\n",
       "      <td>ed5vgdb</td>\n",
       "      <td>Thank you for helping me realize that p&amp;r bloo...</td>\n",
       "      <td>0.041191</td>\n",
       "      <td>0.101370</td>\n",
       "      <td>0.027307</td>\n",
       "      <td>0.037667</td>\n",
       "      <td>0.133593</td>\n",
       "      <td>0.112044</td>\n",
       "      <td>0.326325</td>\n",
       "      <td>0.048431</td>\n",
       "      <td>0.041619</td>\n",
       "      <td>0.039853</td>\n",
       "      <td>0.650492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9400</th>\n",
       "      <td>edbbiz0</td>\n",
       "      <td>Find yourself another pretty, nice girl that d...</td>\n",
       "      <td>0.084577</td>\n",
       "      <td>0.125696</td>\n",
       "      <td>0.046439</td>\n",
       "      <td>0.032907</td>\n",
       "      <td>0.150147</td>\n",
       "      <td>0.105333</td>\n",
       "      <td>0.690024</td>\n",
       "      <td>0.047982</td>\n",
       "      <td>0.046906</td>\n",
       "      <td>0.021315</td>\n",
       "      <td>0.650340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7405</th>\n",
       "      <td>ef6oldj</td>\n",
       "      <td>You've violated rules 4 and 5. Please adhere t...</td>\n",
       "      <td>0.203712</td>\n",
       "      <td>0.118281</td>\n",
       "      <td>0.101460</td>\n",
       "      <td>0.139305</td>\n",
       "      <td>0.037536</td>\n",
       "      <td>0.047997</td>\n",
       "      <td>0.339312</td>\n",
       "      <td>0.076705</td>\n",
       "      <td>0.063593</td>\n",
       "      <td>0.034201</td>\n",
       "      <td>0.650183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17183</th>\n",
       "      <td>eevq1jv</td>\n",
       "      <td>Don't worry, neither have I</td>\n",
       "      <td>0.035832</td>\n",
       "      <td>0.125915</td>\n",
       "      <td>0.030481</td>\n",
       "      <td>0.192093</td>\n",
       "      <td>0.067923</td>\n",
       "      <td>0.084309</td>\n",
       "      <td>0.368459</td>\n",
       "      <td>0.072853</td>\n",
       "      <td>0.044483</td>\n",
       "      <td>0.025330</td>\n",
       "      <td>0.650166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22471</th>\n",
       "      <td>ed5wdvt</td>\n",
       "      <td>Thank you for these helpful points. I’ll read ...</td>\n",
       "      <td>0.044574</td>\n",
       "      <td>0.172682</td>\n",
       "      <td>0.029088</td>\n",
       "      <td>0.067315</td>\n",
       "      <td>0.067848</td>\n",
       "      <td>0.059627</td>\n",
       "      <td>0.224557</td>\n",
       "      <td>0.071543</td>\n",
       "      <td>0.049093</td>\n",
       "      <td>0.042185</td>\n",
       "      <td>0.650080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>453 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID                                              Tweet     anger  \\\n",
       "11708  ed19t6a         Anything is a dildo of you're brave enough  0.077933   \n",
       "18457  ee2flql                             Alway protect yourself  0.090108   \n",
       "16187  ed8ma5b  Thank you for providing an unbiased & sensible...  0.078899   \n",
       "14876  eefvvg0                              Respect for the pedes  0.107745   \n",
       "12620  efcqm9e                         Thank you for your advice!  0.071449   \n",
       "...        ...                                                ...       ...   \n",
       "4284   ed5vgdb  Thank you for helping me realize that p&r bloo...  0.041191   \n",
       "9400   edbbiz0  Find yourself another pretty, nice girl that d...  0.084577   \n",
       "7405   ef6oldj  You've violated rules 4 and 5. Please adhere t...  0.203712   \n",
       "17183  eevq1jv                        Don't worry, neither have I  0.035832   \n",
       "22471  ed5wdvt  Thank you for these helpful points. I’ll read ...  0.044574   \n",
       "\n",
       "       anticipation   disgust      fear       joy      love  optimism  \\\n",
       "11708      0.122461  0.046029  0.173902  0.108056  0.110631  0.501548   \n",
       "18457      0.139424  0.051258  0.156635  0.099426  0.103484  0.469578   \n",
       "16187      0.140619  0.052820  0.121172  0.099130  0.104772  0.321970   \n",
       "14876      0.111379  0.058363  0.107954  0.075680  0.135611  0.324404   \n",
       "12620      0.109628  0.045809  0.110659  0.094731  0.127368  0.294822   \n",
       "...             ...       ...       ...       ...       ...       ...   \n",
       "4284       0.101370  0.027307  0.037667  0.133593  0.112044  0.326325   \n",
       "9400       0.125696  0.046439  0.032907  0.150147  0.105333  0.690024   \n",
       "7405       0.118281  0.101460  0.139305  0.037536  0.047997  0.339312   \n",
       "17183      0.125915  0.030481  0.192093  0.067923  0.084309  0.368459   \n",
       "22471      0.172682  0.029088  0.067315  0.067848  0.059627  0.224557   \n",
       "\n",
       "       pessimism   sadness  surprise     trust  \n",
       "11708   0.072085  0.054894  0.046368  0.852423  \n",
       "18457   0.075968  0.064776  0.046545  0.838971  \n",
       "16187   0.105711  0.081425  0.068242  0.838406  \n",
       "14876   0.083293  0.068631  0.070732  0.826014  \n",
       "12620   0.108275  0.082804  0.063430  0.823668  \n",
       "...          ...       ...       ...       ...  \n",
       "4284    0.048431  0.041619  0.039853  0.650492  \n",
       "9400    0.047982  0.046906  0.021315  0.650340  \n",
       "7405    0.076705  0.063593  0.034201  0.650183  \n",
       "17183   0.072853  0.044483  0.025330  0.650166  \n",
       "22471   0.071543  0.049093  0.042185  0.650080  \n",
       "\n",
       "[453 rows x 13 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pseudo_labeled_dataset.sort_values(by='trust', ascending=False)[pseudo_labeled_dataset['trust'] > 0.65]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
