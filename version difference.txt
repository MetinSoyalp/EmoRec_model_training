+ v1: basic training, just load the data and train it. Some emotions performs poorly. (anticipation, pessimism, surprise, trust)

	Macro - F1-score: 0.4376, Precision: 0.5842, Recall: 0.4004
	Micro - F1-score: 0.6724, Precision: 0.7921, Recall: 0.5841
	Weighted - F1-score: 0.6190, Precision: 0.7225, Recall: 0.5841

+ v2: trying to resolve class inbalance problem by using custom loss function, pos_weight is better, look to it. Improving "try 2" is best choice. Maybe take square root or make it smaller constant.

	- try 1: applying normalized weight to loss function in training. - Almost no change
	class_weights = total_data / ( label_sums + 1e-5 )
	class_weights = class_weights / class_weights.sum()
	loss_function = BCEWithLogitsLoss(weight=class_weights)

	Macro - F1-score: 0.4698, Precision: 0.6848, Recall: 0.4245
	Micro - F1-score: 0.6658, Precision: 0.7663, Recall: 0.5885
	Weighted - F1-score: 0.6246, Precision: 0.7363, Recall: 0.5885

	- try 2: applying unnormalized weight (sum = 83.8916) to positive weight rather than normal weight - Precision took heavy 	blow, maybe normalize first, then apply a constant (maybe 10) to it. Still better than try 1 (low class improvement)
	class_weights = total_data / ( label_sums + 1e-5 )
	loss_function = BCEWithLogitsLoss(pos_weight=class_weights)

	Macro - F1-score: 0.5474, Precision: 0.4448, Recall: 0.8130
	Micro - F1-score: 0.6089, Precision: 0.4745, Recall: 0.8494
	Weighted - F1-score: 0.6693, Precision: 0.5739, Recall: 0.8494

	- try 3: applying unnormalized weight to loss function in training. Some improvement to v1.
	class_weights = total_data / ( label_sums + 1e-5 )
	loss_function = BCEWithLogitsLoss(weight=class_weights)

	Macro - F1-score: 0.4866, Precision: 0.6961, Recall: 0.4368
	Micro - F1-score: 0.6758, Precision: 0.7767, Recall: 0.5980
	Weighted - F1-score: 0.6390, Precision: 0.7549, Recall: 0.5980

	- try 4: applying normalized weight to positive weight rather than normal weight. Holy duck, something is seriously wrong.
	Self note: "making weight smaller than 1" == "ignore label 1 values"
	class_weights = total_data / ( label_sums + 1e-5 )
	class_weights = class_weights / class_weights.sum()
	loss_function = BCEWithLogitsLoss(weight=class_weights)

	Macro - F1-score: 0.0000, Precision: 0.0000, Recall: 0.0000
	Micro - F1-score: 0.0000, Precision: 0.0000, Recall: 0.0000
	Weighted - F1-score: 0.0000, Precision: 0.0000, Recall: 0.0000

	- try 5: applying weight normalized (lowest to be 1) to positive weight, improve upon "try 2". Probably worse than "try 6".
	Wow, it  is better than i expected
	class_weights = total_data / ( label_sums + 1e-5 )
	class_weights = class_weights / class_weights.min()
	loss_function = BCEWithLogitsLoss(pos_weight=class_weights)

	Macro - F1-score: 0.5840, Precision: 0.5646, Recall: 0.6320
	Micro - F1-score: 0.6780, Precision: 0.6476, Recall: 0.7114
	Weighted - F1-score: 0.6918, Precision: 0.6848, Recall: 0.7114

	-try6: "try 5" but add "class_weights = torch.clip(class_weights, min=1.0, max=5.0)" and "torch.log1p(total_data / (label_sums + 1e-5))" 	or sqrt
	class_weights = np.sqrt( total_data / ( label_sums + 1e-5 ) )
	class_weights = class_weights / class_weights.min()
	loss_function = BCEWithLogitsLoss(pos_weight=class_weights)

	Macro - F1-score: 0.5366, Precision: 0.6501, Recall: 0.5082
	Micro - F1-score: 0.6964, Precision: 0.7454, Recall: 0.6535
	Weighted - F1-score: 0.6719, Precision: 0.7246, Recall: 0.6535

	-try7: class weight probably too strong
	class_weights = total_data / ( label_sums + 1e-5 )
	class_weights = class_weights / class_weights.min()
	p_class_weights = np.sqrt( total_data / ( label_sums + 1e-5 ) )
	p_class_weights = p_class_weights / p_class_weights.min()
	loss_function = BCEWithLogitsLoss(weight=class_weights, pos_weight=p_class_weights)

	Macro - F1-score: 0.5317, Precision: 0.6129, Recall: 0.5027
	Micro - F1-score: 0.6662, Precision: 0.7113, Recall: 0.6265
	Weighted - F1-score: 0.6473, Precision: 0.6985, Recall: 0.6265

	-try8: Best for now
	class_weights = np.sqrt( total_data / ( label_sums + 1e-5 ) )
	class_weights = class_weights / class_weights.min()
	p_class_weights = np.sqrt( total_data / ( label_sums + 1e-5 ) )
	p_class_weights = p_class_weights / p_class_weights.min()
	loss_function = BCEWithLogitsLoss(weight=class_weights, pos_weight=p_class_weights)

	Macro - F1-score: 0.5546, Precision: 0.6251, Recall: 0.5239
	Micro - F1-score: 0.6888, Precision: 0.7307, Recall: 0.6515
	Weighted - F1-score: 0.6726, Precision: 0.7132, Recall: 0.6515

+ v3: trying to optimize threshold values - Future work, look to Youden's J statistic

	-try6: Finding best threshold value according to train data and applying it to test - Results are awful, lets scrap that 	idea. - 	Precision-Recall AUC is better for data imbalance
	youden(auc-roc curve) = [0.61, 0.62, 0.53, 0.82, 0.71, 0.76, 0.87, 0.73, 0.86, 0.69, 0.61], NOPE data imbalance amplified

	f1= [0.28, 0.69, 0.12, 0.95, 0.24, 0.83, 0.43, 0.73, 0.92, 0.83, 0.62], NOPE - wrong calculation for it

	Precision-Recall curve = [0.4, 0.29, 0.46, 0.48, 0.47, 0.51, 0.45, 0.41, 0.37, 0.35, 0.34], better?
	Macro - F1-score: 0.5863, Precision: 0.5794, Recall: 0.6091
	Micro - F1-score: 0.6879, Precision: 0.6604, Recall: 0.7179
	Weighted - F1-score: 0.6963, Precision: 0.6820, Recall: 0.7179

	-try7: [0.5, 0.29, 0.46, 0.44, 0.33, 0.5, 0.33, 0.43, 0.42, 0.34, 0.44]
	Macro - F1-score: 0.5703, Precision: 0.5530, Recall: 0.5966
	Micro - F1-score: 0.6732, Precision: 0.6395, Recall: 0.7106
	Weighted - F1-score: 0.6736, Precision: 0.6451, Recall: 0.7106

	-try8: [0.5, 0.32, 0.44, 0.43, 0.37, 0.53, 0.33, 0.44, 0.37, 0.32, 0.44], no difference compared to try 6
	Macro - F1-score: 0.5837, Precision: 0.5731, Recall: 0.6001
	Micro - F1-score: 0.6915, Precision: 0.6661, Recall: 0.7189
	Weighted - F1-score: 0.6915, Precision: 0.6700, Recall: 0.7189

+ v4: dataset balancing - big failure

	- model v1: using v1 script to train, performs better?

	Macro - F1-score: 0.5139, Precision: 0.6352, Recall: 0.4679
	Micro - F1-score: 0.6740, Precision: 0.7586, Recall: 0.6063
	Weighted - F1-score: 0.6481, Precision: 0.7314, Recall: 0.6063

	- model v2: using v2-try 6, threshold: [0.38, 0.3, 0.39, 0.47, 0.41, 0.45, 0.49, 0.34, 0.39, 0.49, 0.48]

	training precision-recall change: anger similar, anticipation similar, disgust similar, fear similar, joy slight 	decrease(similar), love improvement, optimism slight decrease(similar), pessimism high improvement, sadness slight 	decrease(similar), suprise improvement, trust huge improvement

	test result change(without threshold opt): There is no significant improvement in any classes

	Result: love, pessimism, suprise and trust is not ok from goemotions. anticipation had no effect.
	
	With threshold:
	Macro - F1-score: 0.5662, Precision: 0.5781, Recall: 0.5672
	Micro - F1-score: 0.6837, Precision: 0.6784, Recall: 0.6892
	Weighted - F1-score: 0.6838, Precision: 0.6830, Recall: 0.6892

	Without threshold:
	Macro - F1-score: 0.5392, Precision: 0.6121, Recall: 0.4959
	Micro - F1-score: 0.6810, Precision: 0.7436, Recall: 0.6280
	Weighted - F1-score: 0.6653, Precision: 0.7188, Recall: 0.6280

+ v5: semi supervised learning: self-training ( ct = custom threshold)

	-try 1 - iteration 1: It works? More iteration needed. - 117 363 115 300 132 410 200 402 102 501 512 - ct
	
	Macro - F1-score: 0.5810, Precision: 0.6188, Recall: 0.5738
	Micro - F1-score: 0.7071, Precision: 0.7034, Recall: 0.7109
	Weighted - F1-score: 0.6963, Precision: 0.6937, Recall: 0.7109

*	-try 1 - iteration 2: too aggressive growth - 102 356 103 300 102 404 201 401 101 507 500 - ct

	Macro - F1-score: 0.5676, Precision: 0.6394, Recall: 0.5372
	Micro - F1-score: 0.6943, Precision: 0.7243, Recall: 0.6667
	Weighted - F1-score: 0.6831, Precision: 0.7108, Recall: 0.6667

	-try 2 - iteration 1: less aggressive growth rate - ct

	Macro - F1-score: 0.5844, Precision: 0.6244, Recall: 0.5711
	Micro - F1-score: 0.7057, Precision: 0.7106, Recall: 0.7009
	Weighted - F1-score: 0.6977, Precision: 0.7025, Recall: 0.7009

	-try 2 - iteration 2: ct

	Macro - F1-score: 0.5810, Precision: 0.6153, Recall: 0.5684
	Micro - F1-score: 0.7030, Precision: 0.7107, Recall: 0.6955
	Weighted - F1-score: 0.6955, Precision: 0.7010, Recall: 0.6955

*	-try 2 - iteration 3: ct

	Macro - F1-score: 0.5727, Precision: 0.6433, Recall: 0.5464
	Micro - F1-score: 0.7005, Precision: 0.7240, Recall: 0.6785
	Weighted - F1-score: 0.6886, Precision: 0.7129, Recall: 0.6785

*	-try 3 - iteration 1: just first iteration with epoch 5 - ct

	Macro - F1-score: 0.5815, Precision: 0.6086, Recall: 0.5685
	Micro - F1-score: 0.7071, Precision: 0.7138, Recall: 0.7005
	Weighted - F1-score: 0.6982, Precision: 0.7017, Recall: 0.7005

+ v6: back translation + everything else, final try

	- base: main dataset + back translation

	Macro - F1-score: 0.5905, Precision: 0.5754, Recall: 0.6158
	Micro - F1-score: 0.6927, Precision: 0.6669, Recall: 0.7207
	Weighted - F1-score: 0.7000, Precision: 0.6854, Recall: 0.7207

	- iteration 1: majority = low increase - ct

	Macro - F1-score: 0.5921, Precision: 0.5805, Recall: 0.6095
	Micro - F1-score: 0.6944, Precision: 0.6751, Recall: 0.7148
	Weighted - F1-score: 0.6993, Precision: 0.6878, Recall: 0.7148

	- iteration 1-f: 0.3 of all classes - ct

	Macro - F1-score: 0.5865, Precision: 0.5912, Recall: 0.5856
	Micro - F1-score: 0.6955, Precision: 0.6912, Recall: 0.7000
	Weighted - F1-score: 0.6957, Precision: 0.6945, Recall: 0.7000

